{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3659a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a489b3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets: url=the url of the prodoct, headers=the thing needed to get amazon html\n",
    "# return: nothing\n",
    "# the function requests the prodocts html page from amazon, \n",
    "# and scraps all the info we want, \n",
    "# then the list of info back\n",
    "\n",
    "def single_prodocts_handle(url, headers):\n",
    "    if(url == None):\n",
    "        print('single_prodocts_handle got url=None')\n",
    "        return None\n",
    "    page = requests.get(url, headers=headers)\n",
    "    soup1 = BeautifulSoup(page.content, 'html.parser')\n",
    "    soup2 = BeautifulSoup(soup1.prettify(), 'html.parser')\n",
    "    \n",
    "    prodoct_list = []\n",
    "    \n",
    "    # scrap info\n",
    "    title = None\n",
    "    title = soup2.find(id='productTitle')\n",
    "    if title is not None:\n",
    "        title = title.get_text().strip()\n",
    "    prodoct_list.append(title)\n",
    "    #print(title)\n",
    "    \n",
    "    # price\n",
    "    price_text = None\n",
    "    #price = soup2.find_all(\"span\", {\"class\": \"a-offscreen\"})\n",
    "    #apexPriceToPay\n",
    "    price = soup2.find_all(\"span\", {\"class\": \"apexPriceToPay\"})\n",
    "    for ext in price:\n",
    "        price_text = ext.find(\"span\", {\"class\": \"a-offscreen\"}).getText().strip()\n",
    "        #print(place_name)\n",
    "    #PriceToPay\n",
    "    price = soup2.find_all(\"span\", {\"class\": \"priceToPay\"})\n",
    "    for ext in price:\n",
    "        price_text = ext.find(\"span\", {\"class\": \"a-offscreen\"}).getText().strip()\n",
    "        #print(place_name)\n",
    "    prodoct_list.append(price_text)\n",
    "    \n",
    "    # year\n",
    "    year = None\n",
    "    months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    for td in soup2.find_all(\"td\", {\"class\": \"a-size-base prodDetAttrValue\"}):\n",
    "        if any(ext in td.text for ext in months):\n",
    "            year = td.text.strip()\n",
    "            #print(year)\n",
    "            break\n",
    "    prodoct_list.append(year)\n",
    "    \n",
    "    # all the other traits\n",
    "    traits = ['po-brand','po-model_name','po-display.size','po-hard_disk.size','po-cpu_model.family','po-ram_memory.installed_size','po-operating_system','po-graphics_coprocessor']\n",
    "    for trait in traits:\n",
    "        place_trait = soup2.find_all(\"tr\", {\"class\": trait})\n",
    "        if place_trait:\n",
    "            for ext in place_trait:\n",
    "                place_name = ext.find(\"td\", {\"class\": \"a-span9\"})\n",
    "                if(place_name is not None):\n",
    "                    place_name = place_name.getText().strip()\n",
    "                #print(trait,': ', place_name)\n",
    "                prodoct_list.append(place_name)\n",
    "        else:\n",
    "            prodoct_list.append(None)\n",
    "            \n",
    "    return prodoct_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9eed72b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_page_handler(url, headers):\n",
    "    #if(url == None):\n",
    "    #    print('search_page_handler got url=None')\n",
    "    #    return None, None\n",
    "    page = requests.get(url, headers=headers)\n",
    "    #print(page.status_code)\n",
    "    #if page.status_code == :\n",
    "    #    print('You got blocked, ', page.status_code)\n",
    "    soup1 = BeautifulSoup(page.content, 'html.parser')\n",
    "    soup2 = BeautifulSoup(soup1.prettify(), 'html.parser')\n",
    "    \n",
    "    # get prodocts urls\n",
    "    urls = []\n",
    "    for h in soup2.find_all(\"a\",{\"class\":\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"}):\n",
    "        url_string = h.attrs['href']\n",
    "        sep = '/ref='\n",
    "        url_string_stripped = url_string.split(sep, 1)[0]\n",
    "        urls.append('https://www.amazon.com' + url_string_stripped)\n",
    "\n",
    "    # get next page\n",
    "    #print(soup2.find_all(\"a\",{'class':\"s-pagination-item s-pagination-button\"}))\n",
    "    # s-pagination-item s-pagination-next s-pagination-button s-pagination-separator\n",
    "    next_url = soup2.find(\"a\",{\"class\":'s-pagination-next'})\n",
    "    if next_url != None:\n",
    "        next_url = next_url.get(\"href\")\n",
    "        next_url = 'https://www.amazon.com' + next_url\n",
    "    \n",
    "    return next_url, urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cf3579c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU = graphics_coprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "75e78197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_laptop_id_with_screenTouch(url, headers):\n",
    "    t_sleep = 10 #how many sec to sleep between search pages\n",
    "    lst_laptops = []\n",
    "    \n",
    "    # the main loop, how many pages to scrap\n",
    "    for i in range(1, 3):\n",
    "        #print('search page: ', i)\n",
    "        # scrap the search page i (returns the url of next page and prodocts urls)\n",
    "        next_url, prodocts_urls = search_page_handler(url, headers)\n",
    "        \n",
    "        # going over the urls of the prodocts\n",
    "        for url_prodoct in prodocts_urls:\n",
    "            #print(url_prodoct)\n",
    "            # making sure not to call a none url\n",
    "            if(url_prodoct != None):\n",
    "                # gets ID \n",
    "                result = re.search('\\w*dp/(.*)', url_prodoct)\n",
    "                if(result):\n",
    "                    lst_laptops.append(result.group(1))\n",
    "        \n",
    "        url = next_url\n",
    "        if next_url == None:\n",
    "            break\n",
    "        time.sleep(t_sleep) # in secs\n",
    "    \n",
    "    return lst_laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "05f768a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_col_trait(url, headers, df, name_col):\n",
    "    lst_touch = get_list_laptop_id_with_screenTouch(url_touch_bar, headers)\n",
    "    \n",
    "    lst_touch_col = [0] * len(df)\n",
    "    for pro_id in lst_touch:\n",
    "        if pro_id in df['ID']:\n",
    "            index_val = df[df['ID']== pro_id].index.values\n",
    "            lst_touch_col[index_val] = 1\n",
    "    \n",
    "    # add list to df as col\n",
    "    df[name_col] = lst_touch_col\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "77f1b075",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+00A0 (94422239.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Aiden\\AppData\\Local\\Temp\\ipykernel_3528\\94422239.py\"\u001b[1;36m, line \u001b[1;32m18\u001b[0m\n\u001b[1;33m    writer_obj = writer(f_object)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid non-printable character U+00A0\n"
     ]
    }
   ],
   "source": [
    "def scrap_prodocts_from_urls_lst(lst_urls, headers, csv_name):\n",
    "    list_info = []\n",
    "    # going over the urls of the prodocts\n",
    "    for url_prodoct in lst_urls:\n",
    "        if(url_prodoct != None):\n",
    "            # gets info of the prodocts and returns it in a list\n",
    "            list_info = single_prodocts_handle(url_prodoct, headers)\n",
    "            \n",
    "            # get ID\n",
    "            result = re.search('\\w*dp/(.*)', url_prodoct)\n",
    "            if(result):\n",
    "                list_info.insert(0, result.group(1))\n",
    "            \n",
    "            # put prodoct in csv as new row\n",
    "            # Open our existing CSV file in append mode\n",
    "            with open(csv_name, 'a', encoding='UTF8') as f_object:\n",
    "                # Pass this file object to csv.writer() and get a writer object\n",
    "                writer_obj = writer(f_object)\n",
    "                # Pass the list as an argument into the writerow()\n",
    "                writer_obj.writerow(list_info)\n",
    "                # Close the file object\n",
    "                f_object.close()\n",
    "            \n",
    "            list_info = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38213758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_prodoct_urls_in_csv_from_search_pages(url, headers, csv_name):\n",
    "    t_sleep = 10 #how many sec to sleep between search pages\n",
    "    \n",
    "    for i in range(1, 2):\n",
    "        # scrap the search page i (returns the url of next page and prodocts urls)\n",
    "        next_url, prodocts_urls = search_page_handler(url, headers)\n",
    "        \n",
    "        # put urls in csv\n",
    "        \n",
    "        \n",
    "        url = next_url\n",
    "        if next_url == None:\n",
    "            break\n",
    "        time.sleep(t_sleep) # in secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5a1e34cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainfunction(url, headers):\n",
    "    t_sleep = 10 #how many sec to sleep between search pages\n",
    "    lst_columns = ['ID','Name','Price($)','Release_Date','Brand','Model','Display.size(Inches)','Hard_Disk.size(GB)','CPU','RAM_size(GB)','Operating_system','GPU']#,'TouchScreen']\n",
    "    df = pd.DataFrame([], columns = lst_columns)\n",
    "\n",
    "    # the main loop, how many pages to scrap\n",
    "    list_info = []\n",
    "    for i in range(1, 2):\n",
    "        #print('search page: ', i)\n",
    "        # scrap the search page i (returns the url of next page and prodocts urls)\n",
    "        next_url, prodocts_urls = search_page_handler(url, headers)\n",
    "\n",
    "        # going over the urls of the prodocts\n",
    "        for url_prodoct in prodocts_urls:\n",
    "            #print(url_prodoct)\n",
    "            # making sure not to call a none url\n",
    "            if(url_prodoct != None):\n",
    "                # gets info of the prodocts and returns it in a list\n",
    "                list_info = single_prodocts_handle(url_prodoct, headers)\n",
    "                result = re.search('\\w*dp/(.*)', url_prodoct)\n",
    "                if(result):\n",
    "                    list_info.insert(0, result.group(1))\n",
    "                if(len(list_info) == len(lst_columns)):\n",
    "                    df.loc[len(df)] = list_info\n",
    "                #print(list_info)\n",
    "                list_info = []\n",
    "        \n",
    "        url = next_url\n",
    "        if next_url == None:\n",
    "            break\n",
    "        time.sleep(t_sleep) # in secs\n",
    "       \n",
    "    return df\n",
    "    \n",
    "# side note, for 5,000 prodocts, (while a page has ~35), will need 145 sreach pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "14596d79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "next is: <a aria-label=\"Go to next page, page 2\" class=\"s-pagination-item s-pagination-next s-pagination-button s-pagination-separator\" href=\"/s?k=Laptop&amp;i=electronics&amp;bbn=172282&amp;rh=n%3A172282%2Cp_89%3AASUS%7CApple%7CDell%7CHP%7CLenovo&amp;dc&amp;page=2&amp;crid=36LMVV4MB69KG&amp;qid=1673716450&amp;rnid=2528832011&amp;sprefix=laptop%2Caps%2C248&amp;ref=sr_pg_1\">\n",
      "              Next\n",
      "              <svg aria-hidden=\"true\" focusable=\"false\" height=\"12\" viewbox=\"0 0 8 12\" width=\"8\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "<path d=\"M2.126.35a1.28 1.28 0 00-1.761 0 1.165 1.165 0 000 1.695L4.478 6 .365 9.955a1.165 1.165 0 000 1.694 1.28 1.28 0 001.76 0L8 6 2.126.35z\">\n",
      "</path>\n",
      "</svg>\n",
      "</a>\n",
      "next is: https://www.amazon.com/s?k=Laptop&i=electronics&bbn=172282&rh=n%3A172282%2Cp_89%3AASUS%7CApple%7CDell%7CHP%7CLenovo&dc&page=2&crid=36LMVV4MB69KG&qid=1673716450&rnid=2528832011&sprefix=laptop%2Caps%2C248&ref=sr_pg_1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3528\\2943952302.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0murl_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://www.amazon.com/s?k=Laptop&i=electronics&bbn=172282&rh=n%3A172282%2Cp_89%3AASUS%7CApple%7CDell%7CHP%7CLenovo&dc&ds=v1%3AZaooOyrmACgMuUriyaxCaaS3MTydkF4mcXIYLENdXOQ&crid=36LMVV4MB69KG&qid=1671818059&rnid=2528832011&sprefix=laptop%2Caps%2C248&ref=sr_nr_p_89_9'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# start the projoct\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmainfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3528\\4149942381.py\u001b[0m in \u001b[0;36mmainfunction\u001b[1;34m(url, headers)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_prodoct\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[1;31m# gets info of the prodocts and returns it in a list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                 \u001b[0mlist_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msingle_prodocts_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_prodoct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\w*dp/(.*)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl_prodoct\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3528\\4175596035.py\u001b[0m in \u001b[0;36msingle_prodocts_handle\u001b[1;34m(url, headers)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0msoup1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0msoup2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprettify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprodoct_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    331\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize_soup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m                 \u001b[0msuccess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m         \u001b[1;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\builder\\_htmlparser.py\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, markup)\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m             \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mHTMLParseError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\html\\parser.py\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \"\"\"\n\u001b[0;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgoahead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\html\\parser.py\u001b[0m in \u001b[0;36mgoahead\u001b[1;34m(self, end)\u001b[0m\n\u001b[0;32m    170\u001b[0m                     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_starttag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"</\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m                     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_endtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"<!--\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m                     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_comment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\html\\parser.py\u001b[0m in \u001b[0;36mparse_endtag\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    418\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mgtpos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_endtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_cdata_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgtpos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\builder\\_htmlparser.py\u001b[0m in \u001b[0;36mhandle_endtag\u001b[1;34m(self, name, check_already_closed)\u001b[0m\n\u001b[0;32m    191\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malready_closed_empty_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_endtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36mhandle_endtag\u001b[1;34m(self, name, nsprefix)\u001b[0m\n\u001b[0;32m    740\u001b[0m         \"\"\"\n\u001b[0;32m    741\u001b[0m         \u001b[1;31m#print(\"End tag: \" + name)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 742\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    743\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popToTag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnsprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36mendData\u001b[1;34m(self, containerClass)\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[0mcontainerClass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_container\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontainerClass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m             \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontainerClass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_was_parsed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mobject_was_parsed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmost_recent_element\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36mobject_was_parsed\u001b[1;34m(self, o, parent, most_recent_element)\u001b[0m\n\u001b[0;32m    609\u001b[0m         \u001b[0mfix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_element\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m         \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_element\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_sibling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_sibling\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_most_recent_element\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36msetup\u001b[1;34m(self, parent, previous_element, next_element, previous_sibling, next_sibling)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \"\"\"\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m     def setup(self, parent=None, previous_element=None, next_element=None,\n\u001b[0m\u001b[0;32m    158\u001b[0m               previous_sibling=None, next_sibling=None):\n\u001b[0;32m    159\u001b[0m         \"\"\"Sets up the initial relations between this element and\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# MAIN - Where we start\n",
    "# create CSV:\n",
    "csv_file_name = 'test_1.csv'\n",
    "#df.to_csv(csv_file_name)\n",
    "\n",
    "# what will be use\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:108.0) Gecko/20100101 Firefox/108.0\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "#headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "\n",
    "# the starting point (should be a search page og laptops in amazon)\n",
    "url_0 = 'https://www.amazon.com/s?k=Laptop&i=electronics&bbn=172282&rh=n%3A172282%2Cp_89%3AASUS%7CApple%7CDell%7CHP%7CLenovo&dc&ds=v1%3AZaooOyrmACgMuUriyaxCaaS3MTydkF4mcXIYLENdXOQ&crid=36LMVV4MB69KG&qid=1671818059&rnid=2528832011&sprefix=laptop%2Caps%2C248&ref=sr_nr_p_89_9'\n",
    "# start the projoct\n",
    "df = mainfunction(url_0, headers)\n",
    "\n",
    "print(df.head)\n",
    "\n",
    "url_touch_bar = 'https://www.amazon.com/s?k=Laptop&i=electronics&bbn=172282&rh=n%3A565108%2Cp_89%3AASUS%7CApple%7CDell%7CHP%7CLenovo%2Cp_n_feature_fifteen_browse-bin%3A23936568011&dc&ds=v1%3AVnaR7kkl6HGSbLEeS1405RlfMGP7V6%2BRiK0qmHEGCM4&crid=36LMVV4MB69KG&qid=1673705655&rnid=23611390011&sprefix=laptop%2Caps%2C248&ref=sr_nr_p_n_feature_fifteen_browse-bin_1'\n",
    "url_touch_screen = 'https://www.amazon.com/s?k=Laptop&i=electronics&bbn=172282&rh=n%3A565108%2Cp_89%3AASUS%7CApple%7CDell%7CHP%7CLenovo%2Cp_n_feature_fifteen_browse-bin%3A23611396011&dc&ds=v1%3ARGJ%2BVa61Yq9GURz9sQ%2BDyXYRhwE899lNYh%2FghT7u%2FoQ&crid=36LMVV4MB69KG&qid=1673705655&rnid=23611390011&sprefix=laptop%2Caps%2C248&ref=sr_nr_p_n_feature_fifteen_browse-bin_2'\n",
    "url_touch_screen_with_stylus_support = 'https://www.amazon.com/s?k=Laptop&i=electronics&bbn=172282&rh=n%3A565108%2Cp_89%3AASUS%7CApple%7CDell%7CHP%7CLenovo%2Cp_n_feature_fifteen_browse-bin%3A23611397011&dc&ds=v1%3ADnd31uHM0rart9ssD%2Fmazk6C6X97pdWbJ5OcpaIK3nE&crid=36LMVV4MB69KG&qid=1673705655&rnid=23611390011&sprefix=laptop%2Caps%2C248&ref=sr_nr_p_n_feature_fifteen_browse-bin_3'\n",
    "\n",
    "df = add_col_trait(url_touch_bar, headers, df, 'Touch_Bar')\n",
    "print(df['Touch_Bar'].unique())\n",
    "df = add_col_trait(url_touch_screen, headers, df, 'touch_screen')\n",
    "print(df['touch_screen'].unique())\n",
    "df = add_col_trait(url_touch_screen_with_stylus_support, headers, df, 'touch_screen_and_stylus')\n",
    "print(df['touch_screen_and_stylus'].unique())\n",
    "\n",
    "print(df.head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "218e6d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# in mainfunction func\\n# CREATE NEW CSV\\n    csv_name = 'Test_1.csv'\\n    lst_columns = ['Number','Name','Price','Year_relise','Brand','Model','Display.size',\\n    'Hard_Disk.size','CPU','RAM_size','Operating_system','GPU']\\n    with open(csv_name, 'w', encoding='UTF8') as f:\\n        writer = csv.writer(f)\\n        writer.writerow(lst_columns)\\n        f.close()\\n# ADD TO CSV\\n                # Open our existing CSV file in append mode\\n                with open(csv_name, 'a', encoding='UTF8') as f_object:\\n                \\xa0\\xa0\\xa0\\xa0# Pass this file object to csv.writer() and get a writer object\\n                \\xa0\\xa0\\xa0\\xa0writer_object = writer(f_object)\\n                \\xa0\\xa0\\xa0\\xa0# Pass the list as an argument into the writerow()\\n                \\xa0\\xa0\\xa0\\xa0writer_object.writerow(list_info)\\n                \\xa0\\xa0\\xa0\\xa0# Close the file object\\n                \\xa0\\xa0\\xa0\\xa0f_object.close()\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv file code\n",
    "'''\n",
    "# in mainfunction func\n",
    "# CREATE NEW CSV\n",
    "    csv_name = 'Test_1.csv'\n",
    "    lst_columns = ['Number','Name','Price','Year_relise','Brand','Model','Display.size',\n",
    "    'Hard_Disk.size','CPU','RAM_size','Operating_system','GPU']\n",
    "    with open(csv_name, 'w', encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(lst_columns)\n",
    "        f.close()\n",
    "# ADD TO CSV\n",
    "                # Open our existing CSV file in append mode\n",
    "                with open(csv_name, 'a', encoding='UTF8') as f_object:\n",
    "                    # Pass this file object to csv.writer() and get a writer object\n",
    "                    writer_object = writer(f_object)\n",
    "                    # Pass the list as an argument into the writerow()\n",
    "                    writer_object.writerow(list_info)\n",
    "                    # Close the file object\n",
    "                    f_object.close()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d4d0639",
   "metadata": {},
   "source": [
    "# my own data gotten for headers\n",
    "\n",
    "GET /hc/en-us/articles/360031248971-Viewing-your-website-s-headers HTTP/2\n",
    "Host: help.dreamhost.com\n",
    "User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:108.0) Gecko/20100101 Firefox/108.0\n",
    "Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\n",
    "Accept-Language: en-US,en;q=0.5\n",
    "Accept-Encoding: gzip, deflate, br\n",
    "Referer: https://www.google.com/\n",
    "Connection: keep-alive\n",
    "Cookie: __cfruid=76fb5f98d4c056fd1ff5bc75fa6739ea2fe9c1c7-1671902391; __cf_bm=WCTA3OCrqHTq53UuJJaBtpgHeOY718oGq4tESlxcORc-1671902393-0-AduBOiAB3+Zo6hOv7Q3xZDJJN+fpu0ssKFS/tK1xVnAhCJzO8xImPTBmnZGTwkDyHqh9eePMKZWmutEVjYqo+dlsCdKpkhRBcQTnW+/n4AVIriGgvz5bEpTFtNm1n3S7QckS1hNCn7EXa2nlN3uwf9o=\n",
    "Upgrade-Insecure-Requests: 1\n",
    "Sec-Fetch-Dest: document\n",
    "Sec-Fetch-Mode: navigate\n",
    "Sec-Fetch-Site: cross-site\n",
    "Sec-Fetch-User: ?1\n",
    "TE: trailers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8788b910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.com/s?k=Laptop&i=electronics&bbn=172282&rh=n%3A172282%2Cp_89%3AASUS%7CApple%7CDell%7CHP%7CLenovo&dc&page=2&crid=36LMVV4MB69KG&qid=1673097402&rnid=2528832011&sprefix=laptop%2Caps%2C248&ref=sr_pg_1\n",
      "https://www.amazon.com/s?k=Laptop&i=electronics&bbn=172282&rh=n%3A172282%2Cp_89%3AASUS%7CApple%7CDell%7CHP%7CLenovo&dc&page=2&crid=36LMVV4MB69KG&qid=1673097402&rnid=2528832011&sprefix=laptop%2Caps%2C248&ref=sr_pg_1\n"
     ]
    }
   ],
   "source": [
    "# my own: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:108.0) Gecko/20100101 Firefox/108.0\n",
    "# \n",
    "# old_headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:108.0) Gecko/20100101 Firefox/108.0\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "url_0 = 'https://www.amazon.com/s?k=Laptop&i=electronics&bbn=172282&rh=n%3A172282%2Cp_89%3AASUS%7CApple%7CDell%7CHP%7CLenovo&dc&ds=v1%3AZaooOyrmACgMuUriyaxCaaS3MTydkF4mcXIYLENdXOQ&crid=36LMVV4MB69KG&qid=1671818059&rnid=2528832011&sprefix=laptop%2Caps%2C248&ref=sr_nr_p_89_9'\n",
    "next_page = search_page_handler(url_0, headers)\n",
    "print(next_page)\n",
    "# delete everything starting with '/ref='\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "da82a387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ASUS E410 Intel Celeron N4020 4GB 64GB 14-Inch HD LED Win 10 Laptop (Star Black)', '$129.99', 'April 25, 2022', 'ASUS', 'Asus', '14 Inches', '64 GB', 'Celeron', '4 GB', 'Windows 10', None]\n",
      "----\n",
      "['HP Pavilion 15 Laptop, 12th Generation Intel Core i7-1255U Processor, 16 GB RAM, 512 GB SSD, 15.6\" Full HD Display, Windows 11 Pro, Fingerprint Reader, Wi-Fi & Bluetooth, HD Webcam (15-eg2025nr 2022)', '$680.00', 'April 10, 2022', 'HP', 'HP Pavilion Laptop 15-eg2025nr', '15.6 Inches', '512 GB', 'Core i7', '16 GB', 'Windows 11 Pro', None]\n"
     ]
    }
   ],
   "source": [
    "# cheaking the page_prodoct func\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:108.0) Gecko/20100101 Firefox/108.0\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "url_1 = \"https://www.amazon.com/Intel-Celeron-N4020-14-Inch-Laptop/dp/B09YRY6QCX/ref=sr_1_11?crid=36LMVV4MB69KG&keywords=Laptop&qid=1673019112&refinements=p_89%3AASUS%7CApple%7CDell%7CHP%7CLenovo&rnid=2528832011&s=electronics&sprefix=laptop%2Caps%2C248&sr=1-11\"\n",
    "url_2 = \"https://www.amazon.com/HP-Generation-Processor-Fingerprint-15-eg2025nr/dp/B09T513YCJ/ref=sr_1_10?crid=36LMVV4MB69KG&keywords=Laptop&qid=1673019112&refinements=p_89%3AASUS%7CApple%7CDell%7CHP%7CLenovo&rnid=2528832011&s=electronics&sprefix=laptop%2Caps%2C248&sr=1-10\"\n",
    "print(single_prodocts_handle(url_1, headers))\n",
    "print('----')\n",
    "print(single_prodocts_handle(url_2, headers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1012a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# html place link for prodoct in search page\n",
    "#<a class=\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\" \n",
    "#href=\"/Lenovo-Ideapad-Touchscreen-i3-1005G1-Processor/dp/B08B6F1NNR/ref=sr_1_3?crid=38LXN43XVKEAN&amp;keywords=laptop&amp;qid=1671894071&amp;refinements=p_89%3AASUS%7CApple%7CDell%7CHP%7CLenovo&amp;rnid=2528832011&amp;s=electronics&amp;sprefix=lapto%2Caps%2C212&amp;sr=1-3\">\n",
    "#<span class=\"a-size-medium a-color-base a-text-normal\">Lenovo 2022 Newest Ideapad 3 Laptop, 15.6\" HD Touchscreen, 11th Gen Intel Core i3-1115G4 Processor, 8GB DDR4 RAM, 256GB PCIe NVMe SSD, HDMI, Webcam, Wi-Fi 5, Bluetooth, Windows 11 Home, Almond\n",
    "#</span> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07f32b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# html for next page\n",
    "# <a href=\"/s?k=laptop&amp;i=electronics&amp;bbn=172282&amp;rh=n%3A172282%2Cp_89%3AASUS%7CApple%7CDell%7CHP%7CLenovo&amp;dc&amp;page=2&amp;crid=38LXN43XVKEAN&amp;qid=1671894295&amp;rnid=2528832011&amp;sprefix=lapto%2Caps%2C212&amp;ref=sr_pg_2\" \n",
    "# aria-label=\"Go to page 2\" class=\"s-pagination-item s-pagination-button\">\n",
    "# 2</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fbc9e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp for testing the temps\n",
    "URL = 'https://www.amazon.com/Apple-MacBook-16-Inch-Storage-2-6GHz/dp/B08CZT64VP/ref=sr_1_1?crid=38LXN43XVKEAN&keywords=laptop&qid=1671812796&refinements=p_89%3AApple&rnid=2528832011&s=electronics&sprefix=lapto%2Caps%2C212&sr=1-1'\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "\n",
    "page = requests.get(URL, headers=headers)\n",
    "soup1 = BeautifulSoup(page.content, 'html.parser')\n",
    "soup2 = BeautifulSoup(soup1.prettify(), 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "35e4479a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$955.50\n"
     ]
    }
   ],
   "source": [
    "# temp find price\n",
    "#<span class=\"a-offscreen\">$951.48</span>\n",
    "#price = soup2.find_all(\"span\", {\"class\": \"a-offscreen\"})\n",
    "\n",
    "#<span class=\"a-price-whole\">218<span class=\"a-price-decimal\">.</span></span>\n",
    "price = soup2.find_all(\"span\", {\"class\": \"a-price-whole\"})\n",
    "#print(price)\n",
    "\n",
    "#a-price\n",
    "price = soup2.find_all(\"span\", {\"class\": \"a-price\"})\n",
    "#print(price)\n",
    "\n",
    "#apexPriceToPay\n",
    "price = soup2.find_all(\"span\", {\"class\": \"apexPriceToPay\"})\n",
    "for ext in price:\n",
    "    place_name = ext.find(\"span\", {\"class\": \"a-offscreen\"}).getText().strip()\n",
    "    print(place_name)\n",
    "#PriceToPay\n",
    "price = soup2.find_all(\"span\", {\"class\": \"PriceToPay\"})\n",
    "for ext in price:\n",
    "    place_name = ext.find(\"span\", {\"class\": \"a-offscreen\"}).getText().strip()\n",
    "    print(place_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dde381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#<td class=\"a-size-base prodDetAttrValue\"> B08B6F1NNR </td>\n",
    "#year = soup2.find_all(\"td\", {\"class\": \"a-size-base prodDetAttrValue\"})\n",
    "#print(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3333bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "July 15, 2020\n"
     ]
    }
   ],
   "source": [
    "# temp find year\n",
    "months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "for td in soup2.find_all(\"td\", {\"class\": \"a-size-base prodDetAttrValue\"}):\n",
    "    if any(ext in td.text for ext in months):\n",
    "        year = td.text.strip()\n",
    "        print(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6ca29ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "MacBook Pro 16-inch\n",
      "16 Inches\n",
      "512 GB\n",
      "Core i7\n",
      "16 GB\n",
      "Mac OS X 10.0 Cheetah\n",
      "Intel UHD Graphics 630\n"
     ]
    }
   ],
   "source": [
    "# temp 1 finding traits\n",
    "place_trait = soup2.find_all(\"tr\", {\"class\": \"po-brand\"})\n",
    "for ext in place_trait:\n",
    "    place_name = ext.find(\"td\", {\"class\": \"a-span9\"}).getText().strip()\n",
    "    print(place_name)\n",
    "\n",
    "place_trait = soup2.find_all(\"tr\", {\"class\": \"po-model_name\"})\n",
    "for ext in place_trait:\n",
    "    place_name = ext.find(\"td\", {\"class\": \"a-span9\"}).getText().strip()\n",
    "    print(place_name)\n",
    "\n",
    "place_trait = soup2.find_all(\"tr\", {\"class\": \"po-display.size\"})\n",
    "for ext in place_trait:\n",
    "    place_name = ext.find(\"td\", {\"class\": \"a-span9\"}).getText().strip()\n",
    "    print(place_name)\n",
    "#po-hard_disk.size\n",
    "place_trait = soup2.find_all(\"tr\", {\"class\": \"po-hard_disk.size\"})\n",
    "for ext in place_trait:\n",
    "    place_name = ext.find(\"td\", {\"class\": \"a-span9\"}).getText().strip()\n",
    "    print(place_name)\n",
    "#po-cpu_model.family\n",
    "place_trait = soup2.find_all(\"tr\", {\"class\": \"po-cpu_model.family\"})\n",
    "for ext in place_trait:\n",
    "    place_name = ext.find(\"td\", {\"class\": \"a-span9\"}).getText().strip()\n",
    "    print(place_name)\n",
    "#po-ram_memory.installed_size\n",
    "place_trait = soup2.find_all(\"tr\", {\"class\": \"po-ram_memory.installed_size\"})\n",
    "for ext in place_trait:\n",
    "    place_name = ext.find(\"td\", {\"class\": \"a-span9\"}).getText().strip()\n",
    "    print(place_name)\n",
    "#po-operating_system\n",
    "place_trait = soup2.find_all(\"tr\", {\"class\": \"po-operating_system\"})\n",
    "for ext in place_trait:\n",
    "    place_name = ext.find(\"td\", {\"class\": \"a-span9\"}).getText().strip()\n",
    "    print(place_name)\n",
    "#po-graphics_coprocessor\n",
    "place_trait = soup2.find_all(\"tr\", {\"class\": \"po-graphics_coprocessor\"})\n",
    "for ext in place_trait:\n",
    "    place_name = ext.find(\"td\", {\"class\": \"a-span9\"}).getText().strip()\n",
    "    print(place_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d99ab0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "po-brand :  Apple\n",
      "po-model_name :  MacBook Pro 16-inch\n",
      "po-display.size :  16 Inches\n",
      "po-hard_disk.size :  512 GB\n",
      "po-cpu_model.family :  Core i7\n",
      "po-ram_memory.installed_size :  16 GB\n",
      "po-operating_system :  Mac OS X 10.0 Cheetah\n",
      "po-graphics_coprocessor :  Intel UHD Graphics 630\n"
     ]
    }
   ],
   "source": [
    "# temp 2 finding traits (shorter)\n",
    "traiets = ['po-brand','po-model_name','po-display.size','po-hard_disk.size','po-cpu_model.family','po-ram_memory.installed_size','po-operating_system','po-graphics_coprocessor']\n",
    "print(len(traiets))\n",
    "for trait in traiets:\n",
    "    place_trait = soup2.find_all(\"tr\", {\"class\": trait})\n",
    "    for ext in place_trait:\n",
    "        place_name = ext.find(\"td\", {\"class\": \"a-span9\"}).getText().strip()\n",
    "        print(trait,': ', place_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c131603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to do toush screen col\n",
    "'''\n",
    "I will srap the id number from the url of the prodocts\n",
    "and will also do so for page_search with touchscreen ON\n",
    "will use the id to know which ones have touchscreen\n",
    "\n",
    "the id is: \n",
    "https://www.amazon.com/Lenovo-Ideapad-Touchscreen-i3-1005G1-Processor/dp/\n",
    "B08B6F1NNR\n",
    "/ref=(...)\n",
    "\n",
    "between dp/ (id) /ref=\n",
    "\n",
    "I should get the id outside of page_scrap func\n",
    "so the second search_page scraping is faster\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7356a45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# get screentouch with scraping the prodtoct page\n",
    "'''#print(soup2)\n",
    "#table_com = soup2.find_all(\"table\", {\"id\": \"HLCXComparisonTable\"})\n",
    "table_com = soup2.find_all(\"table\", {\"class\": \"a-bordered a-horizontal-stripes a-spacing-none a-size-base comparison_table\"})\n",
    "print(table_com)\n",
    "th_val = soup2.find_all(\"th\", {\"class\":'a-span3 comparison_attribute_name_column comparison_table_first_col'})\n",
    "print(th_val)\n",
    "th_val = soup2.find_all(\"tr\", {\"class\":'comparison_other_attribute_row'})\n",
    "print(th_val)\n",
    "for tr_val in table_com:\n",
    "    print(tr_val)\n",
    "    th_val = tr_val.find(\"th\", {\"class\":'a-span3 comparison_attribute_name_column comparison_table_first_col'}).getText().strip()\n",
    "    print(th_val)\n",
    "    th_text = th_val.find(\"span\", {\"class\": 'a-size-base a-color-base'}).getText().strip()\n",
    "    print(th_text)\n",
    "    if(th_text == 'Human Interface Input'):\n",
    "        val = tr_val.find(\"span\", {\"class\": \"a-span9\"}).getText().strip()\n",
    "        print(val)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3631615f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B08B6F1NNR\n"
     ]
    }
   ],
   "source": [
    "s = 'https://www.amazon.com/Lenovo-Ideapad-Touchscreen-i3-1005G1-Processor/dp/B08B6F1NNR'\n",
    "result = re.search('\\w*dp/(.*)', s)\n",
    "print(result.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c525a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
